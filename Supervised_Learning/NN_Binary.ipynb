{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:51:57.846152Z",
     "start_time": "2020-06-10T04:51:55.166370Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import log_loss, classification_report, precision_recall_curve\n",
    "from sklearn.preprocessing import LabelBinarizer,StandardScaler\n",
    "from sklearn import neural_network\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.activations import sigmoid,relu\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.losses import categorical_crossentropy, CategoricalCrossentropy\n",
    "from keras import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:51:57.853006Z",
     "start_time": "2020-06-10T04:51:57.846152Z"
    }
   },
   "outputs": [],
   "source": [
    "CCE = CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:51:57.864970Z",
     "start_time": "2020-06-10T04:51:57.854999Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:51:57.875970Z",
     "start_time": "2020-06-10T04:51:57.865969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 4), (100, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset = load_iris()\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "\n",
    "X = iris_dataset.data\n",
    "y = iris_dataset.target\n",
    "\n",
    "\n",
    "# lb.fit(y)\n",
    "\n",
    "\n",
    "data = np.concatenate((X[:100],y[:100].reshape(-1,1)), axis = 1)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "\n",
    "X_train = data[:, :-1]\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_train = ss.fit_transform(X_train)\n",
    "\n",
    "y_train = data[: , -1].reshape(-1,1)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:51:57.944793Z",
     "start_time": "2020-06-10T04:51:57.876938Z"
    },
    "code_folding": [
     9,
     15,
     22
    ]
   },
   "outputs": [],
   "source": [
    "def my_sigmoid(x):\n",
    "    \n",
    "    return ( (np.exp(x)) / (1 + np.exp(x) )  )\n",
    "\n",
    "\n",
    "def Relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "\n",
    "def derivative_Relu(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "\n",
    "def relu_activation_derivative(dA, Z):\n",
    "    \n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    \n",
    "    s = sigmoid(x).numpy()\n",
    "    \n",
    "    return s * (1-s)\n",
    "\n",
    "def my_softmax(x, axis = 1):\n",
    "        \n",
    "    x -= np.max(x, axis=axis, keepdims=True)\n",
    "    return np.exp(x) / np.exp(x).sum(axis=axis, keepdims=True)\n",
    "\n",
    "\n",
    "def softmax_grad(softmax):\n",
    "    # Reshape the 1-d softmax to 2-d so that np.dot will do the matrix multiplication\n",
    "    s = softmax.reshape(-1,3)\n",
    "    return np.diagflat(s) - np.dot(s, s.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:51:57.986645Z",
     "start_time": "2020-06-10T04:51:57.945754Z"
    },
    "code_folding": [
     12,
     84,
     108,
     120,
     135
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 , loss: 0.6938988100096825\n"
     ]
    }
   ],
   "source": [
    "def do(lr, epochs = 200, algo = \"Momentum\", nesterov = False, Use_new = False, dictionary = None):\n",
    "    \n",
    "    parameters = { }\n",
    "    \n",
    "    activations = { }\n",
    "    \n",
    "    Derivatives = { }\n",
    "    \n",
    "    Loss = []\n",
    "    \n",
    "    Beta = float(0.9)\n",
    "    \n",
    "    if algo == \"Adam\":\n",
    "        \n",
    "        Beta1 = np.float64(0.9); Beta2 = np.float64(0.999)\n",
    "    \n",
    "    if not Use_new:\n",
    "        \n",
    "        # X row vector (150 rows, 4 columns) => 4,150\n",
    "        theta1 = np.random.randn(4, 3) *np.sqrt(2/4) # = 0.7\n",
    "        theta2 = np.random.randn(3, 3) *np.sqrt(2/3) # = 0.81\n",
    "        theta3 = np.random.randn(3, 1) *np.sqrt(1/6) # = 0.81\n",
    "        \n",
    "    elif Use_new:\n",
    "        theta1 = dictionary[\"theta1\"];\n",
    "        theta2 = dictionary[\"theta2\"];\n",
    "        theta3 = dictionary[\"theta3\"]\n",
    "    \n",
    "\n",
    "    for i in range(epochs):\n",
    "\n",
    "        Z1 = X_train.dot(theta1)\n",
    "        A1 = relu(Z1).numpy()\n",
    "\n",
    "        Z2 = A1.dot(theta2)\n",
    "        A2 = relu(Z2).numpy()\n",
    "\n",
    "        Z3 = A2.dot(theta3)\n",
    "        A3 = sigmoid(Z3).numpy()\n",
    "\n",
    "\n",
    "        LL = log_loss(y_train,A3 )\n",
    "        Loss.append(LL)\n",
    "        if i% 20 == 0:\n",
    "\n",
    "            print( \"Epoch: {} , loss: {}\".format(i,  LL) )\n",
    "\n",
    "        # Backward\n",
    "#         DL_A3 = np.divide(1-y_train, 1-A3) - \\\n",
    "#         np.divide(y_train, A3)\n",
    "\n",
    "#         DA3_Z3 = sigmoid_derivative(Z3) # - y/a + (1-y/ 1-a) * s(x) * (1-s(x))\n",
    "\n",
    "        m = X_train.shape[0]\n",
    "        \n",
    "#         DL_DW3 = ( DZ3_W3.dot( DL_A3 * DA3_Z3   )  ) / X_train.shape[0]\n",
    "#         DL_DZ3 = DL_A3 * DA3_Z3\n",
    "\n",
    "\n",
    "        DL_DZ3 = A3.reshape(-1,1) - y_train.reshape(-1,1)\n",
    "        DZ3_W3 = A2.T\n",
    "        DL_DW3 = (1./m)* ( DZ3_W3.dot( DL_DZ3   )  )\n",
    "        \n",
    "\n",
    "\n",
    "        DL_A2 = (DL_DZ3).dot(theta3.T)\n",
    "\n",
    "#         DA2_Z2 = relu_activation_derivative(DL_A2, Z2)\n",
    "        \n",
    "        DA2_Z2 = derivative_Relu(Z2) # (A2>0)\n",
    "        DZ2_W2 = A1.T\n",
    "\n",
    "        DL_DW2 = (1./m) *(DZ2_W2.dot(DL_A2* DA2_Z2)  )\n",
    "        DL_DZ2 = DL_A2 * DA2_Z2\n",
    "\n",
    "\n",
    "        DL_A1 = DL_DZ2.dot(theta2.T)\n",
    "\n",
    "#         DA1_Z1 = relu_activation_derivative(DL_A1, Z1)\n",
    "        DA1_Z1 = derivative_Relu(Z1)\n",
    "        DZ1_W1 = X_train.T\n",
    "\n",
    "        DL_DW1 = (1./m) * DZ1_W1.dot( DL_A1 * DA1_Z1 )\n",
    "\n",
    "        if algo == \"Momentum\" and Use_new == False:\n",
    "\n",
    "            if i == 0:\n",
    "                m1 = np.zeros(DL_DW1.shape); m2 = np.zeros(DL_DW2.shape); m3 = np.zeros(DL_DW3.shape)\n",
    "\n",
    "            Bm1 = (Beta * m1); Bm2 = (Beta * m2); Bm3 = (Beta * m3)\n",
    "\n",
    "            if nesterov:\n",
    "                # Nesterov Momentum optimization \n",
    "                m1 = Bm1 - ( lr * ( DL_DW1 + Bm1 ) )\n",
    "                m2 = Bm2 - ( lr * ( DL_DW2 + Bm2 ) )\n",
    "                m3 = Bm3 - ( lr * ( DL_DW3 + Bm3 ) )\n",
    "\n",
    "            else:\n",
    "\n",
    "                # Momentum optimization\n",
    "                m1 = Bm1 - ( lr * (DL_DW1) )\n",
    "                m2 = Bm2 - ( lr * (DL_DW2) )\n",
    "                m3 = Bm3 - ( lr * (DL_DW3) )\n",
    "\n",
    "            theta1 += m1\n",
    "            theta2 += m2\n",
    "            theta3 += m3\n",
    "\n",
    "        elif algo == \"Adagrad\" and Use_new == False:\n",
    "\n",
    "            if i == 0:\n",
    "                s1 = np.zeros(DL_DW1.shape); s2= np.zeros(DL_DW2.shape) ; s3 = np.zeros(DL_DW3.shape)\n",
    "\n",
    "            \n",
    "            s1 += np.power(DL_DW1, 2); s2+= np.power(DL_DW2, 2) ; s3 += np.power(DL_DW3, 2)\n",
    "            \n",
    "            theta1 = theta1 - ( (lr * DL_DW1) / np.sqrt(s1 + 10e-10) )  \n",
    "            theta2 = theta2 - ( (lr * DL_DW2) / np.sqrt(s2 + 10e-10) )  \n",
    "            theta3 = theta3 - ( (lr * DL_DW3) / np.sqrt(s3 + 10e-10) )\n",
    "        \n",
    "        elif algo == \"RMSProp\" and Use_new == False:\n",
    "            \n",
    "            if i == 0:\n",
    "                s1 = np.zeros(DL_DW1.shape) ; s2 = np.zeros(DL_DW2.shape)\n",
    "                s3 = np.zeros(DL_DW3.shape)\n",
    "                \n",
    "            \n",
    "            s1 = (Beta * s1) + ( (1 - Beta) * np.power(DL_DW1, 2) )\n",
    "            s2 = (Beta * s2) + ( (1 - Beta) * np.power(DL_DW2, 2) )\n",
    "            s3 = (Beta * s3) + ( (1 - Beta) * np.power(DL_DW3, 2) )\n",
    "            \n",
    "            theta1 = theta1 - ( (lr * DL_DW1) / np.sqrt(s1 + 1e-10) )\n",
    "            theta2 = theta2 - ( (lr * DL_DW2) / np.sqrt(s2 + 1e-10) )\n",
    "            theta3 = theta3 - ( (lr * DL_DW3) / np.sqrt(s3 + 1e-10) )\n",
    "            \n",
    "        elif algo == \"Adam\":\n",
    "            \n",
    "            if i == 0 and Use_new == False:\n",
    "                m1 = np.zeros(DL_DW1.shape, dtype = np.float64)\n",
    "                m2 = np.zeros(DL_DW2.shape,dtype = np.float64)\n",
    "                m3 = np.zeros(DL_DW3.shape, dtype = np.float64)\n",
    "                \n",
    "                s1 = np.zeros(DL_DW1.shape,dtype = np.float64)\n",
    "                s2 = np.zeros(DL_DW2.shape, dtype = np.float64)\n",
    "                s3 = np.zeros(DL_DW3.shape, dtype = np.float64)\n",
    "            \n",
    "            \n",
    "            \n",
    "            m1 = (Beta1 * m1) + ( (1. - Beta1) * DL_DW1 )\n",
    "            m2 = (Beta1 * m2) + ( (1. - Beta1) * DL_DW2 )\n",
    "            m3 = (Beta1 * m3) + ( (1. - Beta1) * DL_DW3 )\n",
    "            \n",
    "            s1 = (Beta2 * s1) + ( (1. - Beta2) * np.square(DL_DW1) )\n",
    "            s2 = (Beta2 * s2) + ( (1. - Beta2) * np.square(DL_DW2)  )\n",
    "            s3 = (Beta2 * s3) + ( (1. - Beta2) * np.square(DL_DW3)  )\n",
    "            \n",
    "            \n",
    "            m1c = m1 / (1. - ( Beta1 ** (i+1) )  )\n",
    "            m2c = m2 / (1. - ( Beta1 ** (i+1))  )\n",
    "            m3c = m3 / (1. - ( Beta1 ** (i+1))  )\n",
    "            \n",
    "            s1c = s1 / (1. - ( Beta2** (i+1)  )  )\n",
    "            s2c = s2 / (1. - ( Beta2 ** (i+1))  )\n",
    "            s3c = s3 / (1. - ( Beta2 ** (i+1))  )\n",
    "            \n",
    "            \n",
    "            tss1 = lr * m1c / ( np.sqrt(s1c) + 1e-8)\n",
    "            tss2 = lr * m2c / ( np.sqrt(s2c) + 1e-8)\n",
    "            tss3 = lr * m3c / ( np.sqrt(s3c) + 1e-8)\n",
    "            \n",
    "            \n",
    "            theta1 = theta1 - tss1\n",
    "            theta2 = theta2 - tss2\n",
    "            theta3 = theta3 - tss3\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "#             theta1 = theta1 - ( lr * DL_DW1 )\n",
    "#             theta2 = theta2 - ( lr * DL_DW2 )\n",
    "#             theta3 = theta3 - ( lr * DL_DW3 )\n",
    "\n",
    "    \n",
    "    parameters[\"theta1\"] = theta1; parameters[\"theta2\"] = theta2; parameters[\"theta3\"] = theta3\n",
    "    \n",
    "    activations[\"A1\"] = A1; activations[\"A2\"] = A2; activations[\"A3\"] = A3\n",
    "    \n",
    "    Derivatives[\"DW1\"] = DL_DW1; Derivatives[\"DW2\"] = DL_DW2; Derivatives[\"DW3\"] = DL_DW3\n",
    "    \n",
    "    return (parameters, activations, Derivatives, Loss)\n",
    "            \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "parameters, activations, Derivatives, Loss = do(lr = 1e-2 , epochs = 1, algo = \"GD\", nesterov = True)\n",
    "\n",
    "# lr 1e-2, epochs = 500, RMSProp : Epoch: 480 , loss: 0.3465736144979975\n",
    "# lr 1e-2, epochs = 500, Momentum, No Nesterov: Epoch: 480 , loss: 0.6925557243217672\n",
    "# lr 1e-2, epochs = 500, Momentum, With Nesterov: Epoch: 480 , loss: 0.6927930940792854\n",
    "\n",
    "\n",
    "\n",
    "# lr 1e-1, epochs = 500, RMSProp : Epoch: 480 , loss: 0.6931471805599453\n",
    "# lr 1e-1, epochs = 500, Momentum, No Nesterov:  Epoch: 480 , loss: 0.34657382330524106\n",
    "# lr 1e-1, epochs = 500, Momentum, With Nesterov: Epoch: 480 , loss: 0.3466761685732003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:51:57.992630Z",
     "start_time": "2020-06-10T04:51:57.988639Z"
    }
   },
   "outputs": [],
   "source": [
    "ti = 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:51:57.997641Z",
     "start_time": "2020-06-10T04:51:57.993627Z"
    }
   },
   "outputs": [],
   "source": [
    "# my_sigmoid( (X_train[ti, : ].reshape(-1,4).dot(theta1)).dot(theta2).dot(theta3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:51:58.004597Z",
     "start_time": "2020-06-10T04:51:57.998612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[ti]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:51:58.045526Z",
     "start_time": "2020-06-10T04:51:58.005594Z"
    }
   },
   "outputs": [],
   "source": [
    "Keras_model  = Sequential()\n",
    "\n",
    "Keras_model.add( Dense(3, activation='relu', use_bias = False, input_shape = (4, ))  )\n",
    "\n",
    "Keras_model.add( Dense (3, activation= 'relu', use_bias=False, input_shape = (3, )))\n",
    "\n",
    "Keras_model.add( Dense (1, activation= 'sigmoid', use_bias=False, input_shape = (3, )))\n",
    "\n",
    "Adam_optim = Adam(learning_rate=1e-2)\n",
    "\n",
    "Keras_model.compile(loss='binary_crossentropy', optimizer=Adam_optim, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:51:59.925463Z",
     "start_time": "2020-06-10T04:51:58.046485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "100/100 [==============================] - 0s 708us/step - loss: 0.5686 - accuracy: 0.7300\n",
      "Epoch 2/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.5551 - accuracy: 0.7700\n",
      "Epoch 3/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.5439 - accuracy: 0.7800\n",
      "Epoch 4/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.5316 - accuracy: 0.7800\n",
      "Epoch 5/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.5183 - accuracy: 0.8100\n",
      "Epoch 6/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.5063 - accuracy: 0.8200\n",
      "Epoch 7/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.4944 - accuracy: 0.8300\n",
      "Epoch 8/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.4829 - accuracy: 0.8400\n",
      "Epoch 9/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.4718 - accuracy: 0.8500\n",
      "Epoch 10/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.4614 - accuracy: 0.8500\n",
      "Epoch 11/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.4515 - accuracy: 0.8500\n",
      "Epoch 12/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.4421 - accuracy: 0.8500\n",
      "Epoch 13/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.4334 - accuracy: 0.8500\n",
      "Epoch 14/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.4254 - accuracy: 0.8500\n",
      "Epoch 15/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.4179 - accuracy: 0.8600\n",
      "Epoch 16/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.4111 - accuracy: 0.8600\n",
      "Epoch 17/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.4049 - accuracy: 0.8600\n",
      "Epoch 18/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3993 - accuracy: 0.8600\n",
      "Epoch 19/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3943 - accuracy: 0.8700\n",
      "Epoch 20/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3898 - accuracy: 0.8700\n",
      "Epoch 21/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3856 - accuracy: 0.8900\n",
      "Epoch 22/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3820 - accuracy: 0.9000\n",
      "Epoch 23/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3788 - accuracy: 0.9000\n",
      "Epoch 24/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3759 - accuracy: 0.9100\n",
      "Epoch 25/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3733 - accuracy: 0.9100\n",
      "Epoch 26/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3710 - accuracy: 0.9100\n",
      "Epoch 27/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3689 - accuracy: 0.9100\n",
      "Epoch 28/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3670 - accuracy: 0.9100\n",
      "Epoch 29/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3653 - accuracy: 0.9100\n",
      "Epoch 30/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3637 - accuracy: 0.9100\n",
      "Epoch 31/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3623 - accuracy: 0.9200\n",
      "Epoch 32/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3610 - accuracy: 0.9200\n",
      "Epoch 33/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3599 - accuracy: 0.9200\n",
      "Epoch 34/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3588 - accuracy: 0.9300\n",
      "Epoch 35/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3578 - accuracy: 0.9300\n",
      "Epoch 36/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3570 - accuracy: 0.9400\n",
      "Epoch 37/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3561 - accuracy: 0.9400\n",
      "Epoch 38/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3554 - accuracy: 0.9400\n",
      "Epoch 39/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3547 - accuracy: 0.9400\n",
      "Epoch 40/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3540 - accuracy: 0.9400\n",
      "Epoch 41/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3534 - accuracy: 0.9400\n",
      "Epoch 42/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3528 - accuracy: 0.9400\n",
      "Epoch 43/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3523 - accuracy: 0.9400\n",
      "Epoch 44/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3518 - accuracy: 0.9700\n",
      "Epoch 45/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3514 - accuracy: 0.9700\n",
      "Epoch 46/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3511 - accuracy: 0.9800\n",
      "Epoch 47/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3509 - accuracy: 0.9800\n",
      "Epoch 48/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3507 - accuracy: 0.9900\n",
      "Epoch 49/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3505 - accuracy: 0.9900\n",
      "Epoch 50/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3503 - accuracy: 0.9900\n",
      "Epoch 51/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3502 - accuracy: 0.9900\n",
      "Epoch 52/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3501 - accuracy: 0.9900\n",
      "Epoch 53/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3499 - accuracy: 0.9900\n",
      "Epoch 54/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3498 - accuracy: 0.9900\n",
      "Epoch 55/700\n",
      "100/100 [==============================] - 0s 9us/step - loss: 0.3497 - accuracy: 0.9900\n",
      "Epoch 56/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3496 - accuracy: 0.9900\n",
      "Epoch 57/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3495 - accuracy: 0.9900\n",
      "Epoch 58/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3494 - accuracy: 0.9900\n",
      "Epoch 59/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3493 - accuracy: 0.9900\n",
      "Epoch 60/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3492 - accuracy: 0.9900\n",
      "Epoch 61/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3492 - accuracy: 0.9900\n",
      "Epoch 62/700\n",
      "100/100 [==============================] - 0s 9us/step - loss: 0.3491 - accuracy: 0.9900\n",
      "Epoch 63/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3490 - accuracy: 0.9900\n",
      "Epoch 64/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3490 - accuracy: 0.9900\n",
      "Epoch 65/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3489 - accuracy: 0.9900\n",
      "Epoch 66/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3488 - accuracy: 0.9900\n",
      "Epoch 67/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3488 - accuracy: 0.9900\n",
      "Epoch 68/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3487 - accuracy: 0.9900\n",
      "Epoch 69/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3487 - accuracy: 0.9900\n",
      "Epoch 70/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3486 - accuracy: 0.9900\n",
      "Epoch 71/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3486 - accuracy: 0.9900\n",
      "Epoch 72/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3485 - accuracy: 0.9900\n",
      "Epoch 73/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3485 - accuracy: 0.9900\n",
      "Epoch 74/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3484 - accuracy: 0.9900\n",
      "Epoch 75/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3484 - accuracy: 0.9900\n",
      "Epoch 76/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3484 - accuracy: 0.9900\n",
      "Epoch 77/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3483 - accuracy: 0.9900\n",
      "Epoch 78/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3483 - accuracy: 0.9900\n",
      "Epoch 79/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3482 - accuracy: 0.9900\n",
      "Epoch 80/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3482 - accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3482 - accuracy: 0.9900\n",
      "Epoch 82/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3481 - accuracy: 0.9900\n",
      "Epoch 83/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3481 - accuracy: 0.9900\n",
      "Epoch 84/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3481 - accuracy: 0.9900\n",
      "Epoch 85/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3481 - accuracy: 0.9900\n",
      "Epoch 86/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3480 - accuracy: 0.9900\n",
      "Epoch 87/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3480 - accuracy: 0.9900\n",
      "Epoch 88/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3480 - accuracy: 0.9900\n",
      "Epoch 89/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3479 - accuracy: 0.9900\n",
      "Epoch 90/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3479 - accuracy: 0.9900\n",
      "Epoch 91/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3479 - accuracy: 0.9900\n",
      "Epoch 92/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3479 - accuracy: 0.9900\n",
      "Epoch 93/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3479 - accuracy: 0.9900\n",
      "Epoch 94/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3478 - accuracy: 0.9900\n",
      "Epoch 95/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3478 - accuracy: 0.9900\n",
      "Epoch 96/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3478 - accuracy: 0.9900\n",
      "Epoch 97/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3478 - accuracy: 0.9900\n",
      "Epoch 98/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3477 - accuracy: 0.9900\n",
      "Epoch 99/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3477 - accuracy: 0.9900\n",
      "Epoch 100/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3477 - accuracy: 0.9900\n",
      "Epoch 101/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3477 - accuracy: 0.9900\n",
      "Epoch 102/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3477 - accuracy: 0.9900\n",
      "Epoch 103/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3476 - accuracy: 0.9900\n",
      "Epoch 104/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3476 - accuracy: 0.9900\n",
      "Epoch 105/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3476 - accuracy: 0.9900\n",
      "Epoch 106/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3476 - accuracy: 0.9900\n",
      "Epoch 107/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3476 - accuracy: 0.9900\n",
      "Epoch 108/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3476 - accuracy: 0.9900\n",
      "Epoch 109/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3475 - accuracy: 0.9900\n",
      "Epoch 110/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3475 - accuracy: 0.9900\n",
      "Epoch 111/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3475 - accuracy: 0.9900\n",
      "Epoch 112/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3475 - accuracy: 0.9900\n",
      "Epoch 113/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3475 - accuracy: 0.9900\n",
      "Epoch 114/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3475 - accuracy: 0.9900\n",
      "Epoch 115/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3475 - accuracy: 0.9900\n",
      "Epoch 116/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3474 - accuracy: 0.9900\n",
      "Epoch 117/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3474 - accuracy: 0.9900\n",
      "Epoch 118/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3474 - accuracy: 0.9900\n",
      "Epoch 119/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3474 - accuracy: 0.9900\n",
      "Epoch 120/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3474 - accuracy: 0.9900\n",
      "Epoch 121/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3474 - accuracy: 0.9900\n",
      "Epoch 122/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3474 - accuracy: 0.9900\n",
      "Epoch 123/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3474 - accuracy: 0.9900\n",
      "Epoch 124/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3473 - accuracy: 0.9900\n",
      "Epoch 125/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3473 - accuracy: 0.9900\n",
      "Epoch 126/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3473 - accuracy: 0.9900\n",
      "Epoch 127/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3473 - accuracy: 0.9900\n",
      "Epoch 128/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3473 - accuracy: 0.9900\n",
      "Epoch 129/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3473 - accuracy: 0.9900\n",
      "Epoch 130/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3473 - accuracy: 0.9900\n",
      "Epoch 131/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3473 - accuracy: 0.9900\n",
      "Epoch 132/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3473 - accuracy: 0.9900\n",
      "Epoch 133/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3472 - accuracy: 0.9900\n",
      "Epoch 134/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3472 - accuracy: 0.9900\n",
      "Epoch 135/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3472 - accuracy: 0.9900\n",
      "Epoch 136/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3472 - accuracy: 0.9900\n",
      "Epoch 137/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3472 - accuracy: 0.9900\n",
      "Epoch 138/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3472 - accuracy: 0.9900\n",
      "Epoch 139/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3472 - accuracy: 0.9900\n",
      "Epoch 140/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3472 - accuracy: 0.9900\n",
      "Epoch 141/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3472 - accuracy: 0.9900\n",
      "Epoch 142/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3472 - accuracy: 0.9900\n",
      "Epoch 143/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3471 - accuracy: 0.9900\n",
      "Epoch 144/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3471 - accuracy: 0.9900\n",
      "Epoch 145/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3471 - accuracy: 0.9900\n",
      "Epoch 146/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3471 - accuracy: 0.9900\n",
      "Epoch 147/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3471 - accuracy: 0.9900\n",
      "Epoch 148/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3471 - accuracy: 0.9900\n",
      "Epoch 149/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3471 - accuracy: 0.9900\n",
      "Epoch 150/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3471 - accuracy: 0.9900\n",
      "Epoch 151/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3471 - accuracy: 1.0000\n",
      "Epoch 152/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3471 - accuracy: 1.0000\n",
      "Epoch 153/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3471 - accuracy: 1.0000\n",
      "Epoch 154/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3471 - accuracy: 1.0000\n",
      "Epoch 155/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3471 - accuracy: 1.0000\n",
      "Epoch 156/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 157/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 158/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 159/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 160/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 162/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 163/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 164/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 165/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 166/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 167/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 168/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 169/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 170/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 171/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 172/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 173/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 174/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 175/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 176/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 177/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 178/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 179/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 180/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 181/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 182/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 183/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 184/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 185/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 186/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 187/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 188/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 189/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 190/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 191/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 192/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 193/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 194/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 195/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 196/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 197/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 198/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 199/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 200/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 201/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 202/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 203/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 204/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 205/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 206/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 207/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 208/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 209/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 210/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 211/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3469 - accuracy: 1.0000\n",
      "Epoch 212/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 213/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 214/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 215/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 216/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 217/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 218/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 219/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 220/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 221/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 222/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 223/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 224/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 225/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 226/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 227/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 228/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 229/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 230/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 231/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 232/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 233/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 234/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 235/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 236/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 237/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 238/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 239/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 241/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 242/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 243/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 244/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 245/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 246/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 247/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 248/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 249/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 250/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 251/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 252/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 253/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 254/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 255/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 256/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 257/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 258/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 259/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 260/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 261/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 262/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 263/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 264/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 265/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 266/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 267/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 268/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 269/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 270/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 271/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 272/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 273/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 274/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 275/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 276/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 277/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 278/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 279/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 280/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 281/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 282/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 283/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 284/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 285/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 286/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 287/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 288/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 289/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 290/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 291/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 292/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 293/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 294/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 295/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 296/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 297/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 298/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 0.9900\n",
      "Epoch 299/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 300/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 301/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 302/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 303/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 304/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 305/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 306/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 307/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 308/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 309/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 310/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 311/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 312/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 313/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 314/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 315/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 316/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 317/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 318/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 319/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 320/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 321/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 322/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 323/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 324/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 325/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 326/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 327/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 328/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 329/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 330/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 331/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 332/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 333/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 334/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 335/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 336/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 337/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 338/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 339/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 340/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 341/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 342/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 343/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 344/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 345/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 346/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 347/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 348/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 349/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 350/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 351/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 352/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 353/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 354/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 355/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 356/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 357/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 358/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 359/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 360/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 361/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 362/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 363/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 364/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 365/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 366/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 367/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 368/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 369/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 370/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 371/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 372/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 373/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 374/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 375/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 376/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 377/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 378/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 379/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 380/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 381/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 382/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 383/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 384/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 385/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 386/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 387/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 388/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 389/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 390/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 391/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 392/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 393/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 394/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 395/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 396/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 397/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 399/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 400/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 401/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 402/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 403/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 404/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 405/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 406/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 407/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 408/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 409/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 410/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 411/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 412/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 413/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 414/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 415/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 416/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 417/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 418/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 419/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 420/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 421/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 422/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 423/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 424/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 425/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 426/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 427/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 428/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 429/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 430/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 431/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 432/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 433/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 434/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 435/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 436/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 437/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 438/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 439/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 440/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 441/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 442/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3467 - accuracy: 1.0000\n",
      "Epoch 443/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 444/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 445/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 446/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 447/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 448/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 449/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 450/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 451/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 452/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 453/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 454/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 455/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 456/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 457/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 458/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 459/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 460/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 461/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 462/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 463/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 464/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 465/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 466/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 467/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 468/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 469/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 470/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 471/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 472/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 473/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 474/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 475/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 476/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 478/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 479/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 480/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 481/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 482/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 483/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 484/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 485/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 486/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 487/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 488/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 489/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 490/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 491/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 492/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 493/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 494/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 495/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 496/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 497/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 498/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 499/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 500/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 501/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 502/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 503/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 504/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 505/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 506/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 507/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 508/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 509/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 510/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 511/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 512/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 513/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 514/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 515/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 516/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 517/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 518/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 519/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 520/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 521/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 522/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 523/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 524/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 525/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 526/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 527/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 528/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 529/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 530/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 531/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 532/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 533/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 534/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 535/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 536/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 537/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 538/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 539/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 540/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 541/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 542/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 543/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 544/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 545/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 546/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 547/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 548/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 549/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 550/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 551/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 552/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 553/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 554/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 555/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 557/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 558/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 559/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 560/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 561/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 562/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 563/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 564/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 565/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 566/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 567/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 568/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 569/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 570/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 571/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 572/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 573/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 574/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 575/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 576/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 577/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 578/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 579/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 580/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 581/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 582/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 583/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 584/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 585/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 586/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 587/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 588/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 589/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 590/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 591/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 592/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 593/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 594/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 595/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 596/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 597/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 598/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 599/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 0.9900\n",
      "Epoch 600/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 601/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 602/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 603/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 604/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 605/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 606/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 607/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 608/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 609/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 610/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 611/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 612/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 613/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 614/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 615/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 616/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 617/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 618/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 619/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 620/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 621/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 622/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 623/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 624/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 625/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 626/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 627/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 628/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 629/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 630/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 631/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 632/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 633/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 634/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 635/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 636/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 637/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 638/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 639/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 640/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 641/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 642/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 643/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 644/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 645/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 646/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 647/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 648/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 649/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 650/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 651/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 652/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 653/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 654/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 655/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 656/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 657/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 658/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 659/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 660/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 0.9900\n",
      "Epoch 661/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 662/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 663/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 664/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 665/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 666/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 667/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 668/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 669/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 670/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 671/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 672/700\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 673/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 674/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 675/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 676/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 677/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 678/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 679/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 680/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 681/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 682/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 683/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 684/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 685/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 686/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 687/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 688/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 689/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 690/700\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 691/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 692/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 693/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 694/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 695/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 696/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 697/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 698/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 699/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 700/700\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.3466 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x288c5ad42e8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Keras_model.fit(X_train, y_train, epochs=700, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:51:59.945464Z",
     "start_time": "2020-06-10T04:51:59.926495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Keras_model.predict_proba(X_train[ti, : ].reshape(-1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:51:59.972337Z",
     "start_time": "2020-06-10T04:51:59.946433Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Amith_Learning\\Anaconda3\\envs\\Amith_Learning\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(3,), learning_rate_init=0.1, shuffle=False,\n",
       "              solver='sgd')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = neural_network.MLPClassifier(hidden_layer_sizes=(3,), activation = \"relu\",\n",
    "                                 solver = 'sgd',\n",
    "                                 learning_rate_init = 1e-1,\n",
    "                                 max_iter = 200,\n",
    "                                 shuffle = False)\n",
    "\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:51:59.978323Z",
     "start_time": "2020-06-10T04:51:59.974358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.n_layers_, nn.n_outputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:51:59.985301Z",
     "start_time": "2020-06-10T04:51:59.979318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0024201907071314103"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:51:59.992284Z",
     "start_time": "2020-06-10T04:51:59.986299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.99830525, 0.00169475]]), array([0.]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict_proba(X_train[ti, : ].reshape(1,-1)), nn.predict(X_train[ti, : ].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:52:00.145874Z",
     "start_time": "2020-06-10T04:51:59.993316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAHICAYAAAALEE23AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdeZgddZn28fvuJeksne7skIUkxIACYsQQVAjCoIgswigqCAq+A4iMjI6OI7gwDG7o6MjMiC8iIoPAIKIgAuLCFmD0hQYCEjAQQkKaAOkEsu+d5/2jqkOl6eV0cqpPdef7ua6++tR6nvqdOqfvrl/VKUeEAAAAUAxVlS4AAAAAryGcAQAAFAjhDAAAoEAIZwAAAAVCOAMAACgQwhkAAECBEM7QJdtft73M9ks7sOw9ts/Iqa4v2b6ii+mn274/j+cuKttX2f56pevozC76mnS5n+7KbIftN3QyLbfPjh1le43tPXNY72G2m8u93iKw/Vvbp1W6jr6optIFIGF7oaQzIuKPla6lje2Jkj4vaVJELK10PVkR8c22x7YnS3pOUm1EbKlUTW1sXyWpOSK+UulaUFnZ/RR9W0QMrXQNvcn2PZKuiYiS/rmwfaGkN0TEqW3jIuJ9+VTX/3HkDF2ZJGl50YKZbf6pQOGxn1aWE/yNQ5/EjltwtgfavsT2kvTnEtsD02mjbN9qe4XtV2zf1/ZhZPuLtl+wvdr2PNtHdLL+BttX226xvcj2V2xX2X63pD9IGpcezr+qg2WHp8/fYvvV9PGETp6n2vb30i7S52x/Ou3WqEmnj7N9S7od822fmVn2Qts32r7G9ipJp6fjrklnmZ3+XpHW+o7Mst9Na3vO9vsy4+9Ju2z/N13mN7ZH2r7W9irbD6VH5Dp7XX5h+yXbK23Ptr1vOv4sSadI+ue29Xay/Btt/yHd3nm2P5yZdoztR9M6Fqf/kWaXPSSte0U6/fTM5OG2b0tf9/9ne2oX2/D2zHoes31Yu/b5lu0H0238te0Rmenvtz03XfYe22/KTJto+1fpfrHc9g/aPW+Hr0l3OtvuzvbhdNrpth+w/f10uQW235mOX2x7qTPdLk66hi9LX5vVtu+1PSkz/T/S5VbZftj2rMy0LvdT25PTff4028+n74UvZ5YfZPu/07Z5yvY/u4vurnQ7Hkpfn4dsvzMdf7jtv2Tm+6PtBzPD99s+IX280PY/2X48Xc/Pbdd18nxTbd+VvqbLnLxXGjPTu1yX7S/YftHJ59j/6frV3u55d0/X+U/pcHf77TdsPyBpnaQ9bX8ibc/V6ev/ycz8nX6GdlDHtm7YdD/5oZNuuzXpPrabk8/nV23/1fZb27XN+bafTKf/tIt2Hmf7l+n+/Jztf8hMu9DJZ8816fb8xfZe6bqXpvvmkZn5G2z/JG33F5x85lWn005P94XXvR9tf0PSLEk/SLfvB+n4Dvd/20dJ+pKkj6TzP5Z5Pc5IH1c5eW8uSmu92nZDOq3L98YuKSL4KcCPpIWS3t3B+Isk/VnSGEmjJf2vpK+l074l6TJJtenPLEmWtLekxZLGpfNNljS1k+e9WtKvJdWn8z0t6e/SaYcp6Z7rrOaRkj4oaXC6/C8k3ZyZfo+SrlpJOlvSk5ImSBou6Y+SQlJNOv1eST+UVCdpuqQWSUek0y6UtFnSCUr+oRiUjrsms33b1pWOOz1d5kxJ1ZI+JWmJJGdqmy9pqqSGtLanJb1bSXf/1ZJ+2sW2/590mwdKukTSnMy0qyR9vYtlh6SvzyfS5zpA0jJJ+2ba/c3ptu4v6WVJJ6TT9pC0WtLJ6Ws+UtL0zPO+Imlmut5rJV3fSQ3jJS2XdHT6PO9Jh0dn2ucFSful9f4y0957SVqbLlMr6Z/TthyQtvVjkr6fLlcn6ZBSXpNu3h9dbXdX+/DpkrakbV0t6euSnpd0afraHZmud2imDVdLOjSd/h+S7s/UcWr63DVKuvxfklTXw/30x+m0t0jaKOlN6fSLlbwPhit5nzyuTt5/kkZIelXSx9JaTk6HR6Ztvl7SqHTaS2k716fPu17SyMznzoOSxqXrfErS2Z085xvS13ygks+i2ZIuafcZ1uG6JB2lZD9u25+uS9viDZ081z2Szsi8nmf1YL99XtK+6bbXSjpGyfvckt6lJLQd0NVnaCc1batXyX6yTNLb0va+S8mpFR/Xa/vZ3e3a5glJE9O2eUDpZ4Qyn7PpNj0s6QIl76c9JS2Q9N7MPrZB0nv12ufUc5K+nNZ/pqTnMs97s6QfpW0+Jn19PtmDz8gz2rVBd/v/NR29jpnPzPnpNg2V9CtJPyvxvXGIpBWl/j3tDz8VL4Cf9IXoPJw9K+nozPB7JS1MH1+k5I/SG9ot8wZJS5UEjdounrM6fQPskxn3SUn3pI+3fWiUuA3TJb2aGc6+Me9q+1BIh9+dvhlr0g+sVkn1menfknRV+vhCSbPbPde2DwJ1Hs7mZ4YHp/Pslqnty5np35P028zwccoErm62uzFdd0M6fJW6DmcfkXRfu3E/kvQvncx/iaTvp4/Pl3RTJ/NdJemKzPDRkv7aybxfbPtgzIz7naTTMu1zcWbaPpI2pfvMVyXdkJlWpSTIHSbpHUqCdU0Hz9nla9JNG3e43SXsw6dLeiYz7c3pc47NjFuu7QPu9ZlpQ9N9c2Indb0q6S093E8nZKY/KOmk9PG2P8Lp8BnqPJx9TNKD7cb9SdLp6eP7JH1A0tsl/V7SDUoC0uGSHs8ss1DSqZnh70i6rMT9/gRJj5ayLklXttuf9lL34ezf03We3MP99qJu6r5Z0mfSxx1+hnayXPtw9uPMtHMlPdVuP1uRGV6oTOhV8t58Nn18mF4LZwdJer6Dff+nmf3pD5lpx0laI6k6Ha5P62yUNFbJe2NQZv6TlYZGlfYZeUZn7dHJ/t9VOLtT0jmZaXsrCYc16ua9sSv+0K1ZfOMkLcoML0rHSdK/KflP5Pfp4frzJCki5kv6rJI3y1Lb19sep9cbpeS/s/brH19KYbYH2/5Reph6lZL/pBvbDpt3sB2LM8OL2017JSJWd1FHdv5SbbvCNCLWpQ+zJ/W+nHm8voPhDk8AdtJFe7HtZ9PtXphOGlViXZMkHZR2paywvUJJV+hu6foPsn132q2xUslRx7Z1T1QS2DuTvap2XWfbkNbwoXY1HCJp98w82TZfpOQ/81Fqt09GxNZ03vFpfYui8wszuntNOtPZdpeyD7d/XRURXb3W27Y7ItYoORo5TpJsfz7tIluZtlmDtn/dS9lPO3uNunqPtNf+c0HafrvvVfJH/9D08T1Kjhq9Kx0upZ7t2B6Tfpa8kO731+j1+3yp29a+9o6coiT035gZ19P9VrbfZ/vPabflCiXBqK3uDj9DS9TTz4/229/RZ/IkJaeSZLfvS0qCVmfPuywiWjPDSp97kpL37IuZdf1IyRG0Nj16P5aw/3elo79lNe22rdTPr36PcFZ8S5S8ydrskY5TRKyOiM9HxJ5K/oP6nNNzyyLiuog4JF02JH27g3UvU/KfS/v1v1BibZ9X8t/PQRExTMkfAinpPmjvRSVdNW0mZh4vkTTCdn0XdUQXdXQ1LQ8flXS8kqN/DUr+65Ne2+7u6lks6d6IaMz8DI2IT6XTr5N0i5KjNQ1Kul2cWbbT88h6YLGSIxDZGoZExMWZebKv0R5K9pVlardP2nY67wvpevdw+U+G72y7d3Yf7si27bY9VEk31JL0/JovSvqwpOER0Shppbbf33dmX+zqPdJe+88Fafvtbh/O7lXn4axU31Kyffun7/dT1fF7vSMv6vX7U3cuVPL6Xpf5h6+U/Xbba+Dk/NxfSvqukqOljZJub6u7q8/QHLTf/iUdzLNYSbdkdvvqI+LoHXi+xUqOnI3KrGtYROxb4vLb7csl7P/d7fsd/S3bou3DJlKEs2KptV2X+amR9D+SvmJ7tO1RSs5FaDvB+Fjbb0j/OK5S0v3Santv23+TfjBtUPLfVGv7J0v/27pB0jds1zs58flzbesvQX267hVOThb/ly7mvUHSZ2yPd3IS8RczdSxWci7dt9Lt3l/S3yk5Z6oULZK2KjmXoTfUK/nQW66kK6D91yW83E0tt0ray/bHbNemPwf6tZPq65UcSdxge6aSMNjmWknvtv1h2zVOLmKYvgPbcI2k42y/Nz0SWOfk+5ay4eBU2/vYHqyk++fGzD5zjO0jbNcqCekblbyGDyr5Q3yx7SHpeg8upSAnJzvf08nkDre7DPtwR452cvHBAElfk/T/0n20XskfkxZJNbYvkDRsJ56nvRskne/kQpvxkj7dxby3K9mHPpq2x0eUdD3fmk7/XyX/OM1U0v05V+kRW712AU1P1SvpQluR1veFHix7g5ILJNr2p64+K9pslvQhJedL/czJifql7LdZA5ScI9ciaYuTE96zJ8x3+Bnag+3qib+3PSH9rPySpJ93MM+DklY5uaBrULqN+9k+sKdPFhEvKunS/p7tYU5OyJ9q+10lrqL951h3+//Lkia78ytk/0fSP9qekv7T801JP+/iKPsujXBWLLcrCTttPxcqObG0ScnJwX+R9Eg6TpKmKTmxfo2S801+GBH3KPkwuljJf50vKTmM/aVOnvNcJSd3L5B0v5KjNleWWO8lSk7eXKbkooU7upj3x0o+KB6X9Gi6rVv02gfhyUqOQC2RdJOS86/+UEoR6eH4b0h6ID18//YS699RVys5JP+CkgsJ/txu+k8k7ZPWcnMH9a5W8gfiJCXb+5KSI5sD01nOkXSR7dVKwvgNmWWfV9It83kl3W1zlJw82yNp2DheyX7RouS/7C9o+8+Enyk5t+YlJSc9/0O67DwlR03+S8lrf5yk4yJiUxqWjlNy3uPzkpqVnGNXiolKTpTuqN6utntn9uGOXKckPLyi5ITvU9Lxv5P0WyUnqC9S8o/PjnS3d+YiJe31nJL39Y1KQu/rRMRySccqaY/lSi7KODYilqXT1yr5rJgbEZvSxf6kpMt5R78a51+VXLyyUtJtSk7oLklE/FbJ58VdSroR7ypxuU1Kzp0bo+Q1fUHd77fZ5Vcr2W9vUHJ+1EeVHJVu09lnaB6uU/IZuCD9ed0XRmfeP9OV7AfLJF2h5Aj9jvi4koD6pJLtv1HbdwF35T8knejkSs7/VPf7/y/S38ttP9LB+q5U8pkyW8m2bVDy3u2W7Vm215RYd7/QdlUG0KvS/2Avi4j2XTMoAPfwCyjL9JxzlFyhu7y3nrODGq5SQb5A2PanlJwQXeqRDhSUC/gl4yg2jpyhV6SH6I9Ou2DGKzkycVOl60JxRMT0SgazSnPyfV4Hp91Peys5KsZ7BNgFEc7QW6ykW+RVJd2aTynpsgOQGKDkarrVSrr9fq3ku/8A7GLo1gQAACgQjpwBAAAUCOEMAACgQAhnAAAABUI4AwAAKBDCGQAAQIEQzgAAAAqEcAYAAFAghDMAAIACIZwBAAAUCOEMAACgQAhnAAAABUI4AwAAKBDCGQAAQIEQzgAAAAqEcAYAAFAghDMAAIACqal0AeU0atSomDx5cqXLAAAA6NbDDz+8LCJGtx/fr8LZ5MmT1dTUVOkyAAAAumV7UUfj6dYEAAAoEMIZAABAgRDOAAAACqRfnXMGAACKafPmzWpubtaGDRsqXUqvq6ur04QJE1RbW1vS/IQzAACQu+bmZtXX12vy5MmyXelyek1EaPny5WpubtaUKVNKWoZuTQAAkLsNGzZo5MiRu1QwkyTbGjlyZI+OGOYazmwfZXue7fm2z+tg+hdsz0l/nrDdantEKcsCAIC+ZVcLZm16ut25hTPb1ZIulfQ+SftIOtn2Ptl5IuLfImJ6REyXdL6keyPilVKWBQAA6I/yPHI2U9L8iFgQEZskXS/p+C7mP1nS/+zgsgAAAF1qbm7W8ccfr2nTpmnq1Kn6zGc+o02bNlW6rNfJM5yNl7Q4M9ycjnsd24MlHSXplzuw7Fm2m2w3tbS07HTRAACg/4kIfeADH9AJJ5ygZ555Rk8//bTWrFmjL3/5y5Uu7XXyDGcddbBGJ/MeJ+mBiHilp8tGxOURMSMiZowe/brbUwEAAOiuu+5SXV2dPvGJT0iSqqur9f3vf19XXnml1q1bp6OPPlqPP/64JOmtb32rLrroIknSV7/6VV1xxRW65557dNhhh+nEE0/UG9/4Rp1yyimK6CzW7Jw8v0qjWdLEzPAESUs6mfckvdal2dNlAQBAX/LZz0pz5pR3ndOnS5dc0unkuXPn6m1ve9t244YNG6Y99thD8+fP16GHHqr77rtPkydPVk1NjR544AFJ0v33369TTz1VL774oh599FHNnTtX48aN08EHH6wHHnhAhxxySHm3Q/keOXtI0jTbU2wPUBLAbmk/k+0GSe+S9OueLgsAAFCKiOjwqsm28bNmzdLs2bN1//3365hjjtGaNWu0bt06LVy4UHvvvbckaebMmZowYYKqqqo0ffp0LVy4MJdacztyFhFbbH9a0u8kVUu6MiLm2j47nX5ZOuvfSvp9RKztbtm8agUAAL2oiyNcedl33331y1/+crtxq1at0uLFizV16lTV1NSoqalJe+65p97znvdo2bJl+vGPf7zd0baBAwdue1xdXa0tW7bkUmuu33MWEbdHxF4RMTUivpGOuywTzBQRV0XESaUsCwAAsCOOOOIIrVu3TldffbUkqbW1VZ///Od1+umna/DgwRowYIAmTpyoG264QW9/+9s1a9Ysffe739WsWbN6vVbuEAAAAPo927rpppv0i1/8QtOmTdNee+2luro6ffOb39w2z6xZszR27FgNHjxYs2bNUnNzc0XCmfO60qASZsyYEU1NTZUuAwAAtPPUU0/pTW96U6XLqJiOtt/2wxExo/28HDkDAAAoEMIZAABAgRDOAAAACoRwBgAAUCCEMwAAgAIhnAEAABQI4QwAAOwShg4duu3x7bffrmnTpun555+vYEUdI5wBAIBdyp133qlzzz1Xd9xxh/bYY4+Slmltbc25qtcQzgAAwC7jvvvu05lnnqnbbrtNU6dOlSRdc801mjlzpqZPn65PfvKT24LY0KFDdcEFF+iggw7Sn/70J1100UU68MADtd9+++mss85S2xf5/+d//qf22Wcf7b///jrppNfdkbLHcrvxOQAAQEc+e8dnNeelOWVd5/TdpuuSo7q+ofrGjRt1/PHH65577tEb3/hGSck39//85z/XAw88oNraWp1zzjm69tpr9fGPf1xr167Vfvvtp4suukiStM8+++iCCy6QJH3sYx/TrbfequOOO04XX3yxnnvuOQ0cOFArVqzY6W3hyBkAANgl1NbW6p3vfKd+8pOfbBt355136uGHH9aBBx6o6dOn684779SCBQskSdXV1frgBz+4bd67775bBx10kN785jfrrrvu0ty5cyVJ+++/v0455RRdc801qqnZ+eNeHDkDAAC9qrsjXHmpqqrSDTfcoHe/+9365je/qS996UuKCJ122mn61re+9br56+rqVF1dLUnasGGDzjnnHDU1NWnixIm68MILtWHDBknSbbfdptmzZ+uWW27R1772Nc2dO3enQhpHzgAAwC5j8ODBuvXWW3XttdfqJz/5iY444gjdeOONWrp0qSTplVde0aJFi163XFsQGzVqlNasWaMbb7xRkrR161YtXrxYhx9+uL7zne9oxYoVWrNmzU7VyJEzAACwSxkxYoTuuOMOHXroobrkkkv09a9/XUceeaS2bt2q2tpaXXrppZo0adJ2yzQ2NurMM8/Um9/8Zk2ePFkHHnigpOQqzlNPPVUrV65UROgf//Ef1djYuFP1ue1Kg/5gxowZ0dTUVOkyAABAO0899ZTe9KY3VbqMiulo+20/HBEz2s9LtyYAAECBEM4AAAAKhHAGAAB6RX86laonerrdhDMAAJC7uro6LV++fJcLaBGh5cuXq66uruRluFoTAADkbsKECWpublZLS0ulS+l1dXV1mjBhQsnzE84AAEDuamtrNWXKlEqX0SfQrQkAAFAghDMAAIACIZwBAAAUCOEMAACgQAhnAAAABUI4AwAAKBDCGQAAQIEQzgAAAAqEcAYAAFAghDMAAIACIZwBAAAUCOEMAACgQAhnAAAABUI4AwAAKBDCGQAAQIEQzgAAAAqEcAYAAFAghDMAAIACyTWc2T7K9jzb822f18k8h9meY3uu7Xsz4xfa/ks6rSnPOgEAAIqiJq8V266WdKmk90hqlvSQ7Vsi4snMPI2SfijpqIh43vaYdqs5PCKW5VUjAABA0eR55GympPkRsSAiNkm6XtLx7eb5qKRfRcTzkhQRS3OsBwAAoPDyDGfjJS3ODDen47L2kjTc9j22H7b98cy0kPT7dPxZnT2J7bNsN9luamlpKVvxAAAAlZBbt6YkdzAuOnj+t0k6QtIgSX+y/eeIeFrSwRGxJO3q/IPtv0bE7NetMOJySZdL0owZM9qvHwAAoE/J88hZs6SJmeEJkpZ0MM8dEbE2PbdstqS3SFJELEl/L5V0k5JuUgAAgH4tz3D2kKRptqfYHiDpJEm3tJvn15Jm2a6xPVjSQZKesj3Edr0k2R4i6UhJT+RYKwAAQCHk1q0ZEVtsf1rS7yRVS7oyIubaPjudfllEPGX7DkmPS9oq6YqIeML2npJust1W43URcUdetQIAABSFI/rPaVozZsyIpia+Eg0AABSf7YcjYkb78dwhAAAAoEAIZwAAAAVCOAMAACgQwhkAAECBEM4AAAAKhHAGAABQIIQzAACAAiGcAQAAFAjhDAAAoEAIZwAAAAVCOAMAACgQwhkAAECBEM4AAAAKhHAGAABQIIQzAACAAiGcAQAAFAjhDAAAoEAIZwAAAAVCOAMAACgQwhkAAECBEM4AAAAKhHAGAABQIIQzAACAAiGcAQAAFAjhDAAAoEAIZwAAAAVCOAMAACgQwhkAAECBEM4AAAAKhHAGAABQIIQzAACAAiGcAQAAFAjhDAAAoEAIZwAAAAVCOAMAACgQwhkAAECBEM4AAAAKhHAGAABQIIQzAACAAiGcAQAAFAjhDAAAoEByDWe2j7I9z/Z82+d1Ms9htufYnmv73p4sCwAA0N/U5LVi29WSLpX0HknNkh6yfUtEPJmZp1HSDyUdFRHP2x5T6rIAAAD9UZ5HzmZKmh8RCyJik6TrJR3fbp6PSvpVRDwvSRGxtAfLAgAA9Dt5hrPxkhZnhpvTcVl7SRpu+x7bD9v+eA+WlSTZPst2k+2mlpaWMpUOAABQGbl1a0pyB+Oig+d/m6QjJA2S9Cfbfy5x2WRkxOWSLpekGTNmdDgPAABAX5FnOGuWNDEzPEHSkg7mWRYRayWttT1b0ltKXBYAAKDfybNb8yFJ02xPsT1A0kmSbmk3z68lzbJdY3uwpIMkPVXisgAAAP1ObkfOImKL7U9L+p2kaklXRsRc22en0y+LiKds3yHpcUlbJV0REU9IUkfL5lUrAABAUTii/5ymNWPGjGhqaqp0GQAAAN2y/XBEzGg/njsEAAAAFAjhDAAAoEAIZwAAAAVCOAMAACgQwhkAAECBEM4AAAAKhHAGAABQIIQzAACAAiGcAQAAFAjhDAAAoEAIZwAAAAVCOAMAACgQwhkAAECBEM4AAAAKhHAGAABQIIQzAACAAiGcAQAAFAjhDAAAoEAIZwAAAAVCOAMAACgQwhkAAECBEM4AAAAKhHAGAABQIIQzAACAAiGc9cBdz92l/138v5UuAwAA9GOEsx743O8+p28/8O1KlwEAAPoxwlkPDBs4TKs2rqp0GQAAoB8jnPUA4QwAAOStprsZbO8l6QuSJmXnj4i/ybGuQho2cJjmLZ9X6TIAAEA/1m04k/QLSZdJ+rGk1nzLKTaOnAEAgLyVEs62RMT/zb2SPqB+QD3hDAAA5KrTc85sj7A9QtJvbJ9je/e2cen4Xc6wgcO0YcsGbW7dXOlSAABAP9XVkbOHJYUkp8NfyEwLSXvmVVRRDRs4TJK0etNqjRi0S+ZTAACQs07DWURM6c1C+oK2cLZq4yrCGQAAyEW3X6Vh++9tN2aGh9s+J9+yiikbzgAAAPJQyvecnRkRK9oGIuJVSWfmV1Jx1Q+sl0Q4AwAA+SklnFXZbjvvTLarJQ3Ir6Ti4sgZAADIWylfpfE7STfYvkzJhQBnS7oj16oKatsFARtXV7gSAADQX5USzr4o6ZOSPqXkys3fS7oiz6KKqi2crdy4ssKVAACA/qrbcBYRW23/RNL9So6czYuIXfJOAQ0DGyRJKzcQzgAAQD5KubfmYZL+W9JCJUfOJto+LSJm51ta8QwdMFRVruLIGQAAyE0pFwR8T9KREfGuiDhU0nslfb+Ulds+yvY82/Ntn9fB9MNsr7Q9J/25IDNtoe2/pOObSt2gPNlWY12jVmxY0f3MAAAAO6CUc85qI2Je20BEPG27truF0qs6L5X0HknNkh6yfUtEPNlu1vsi4thOVnN4RCwrocZeQzgDAAB5KiWcNaXnnP0sHT5Fya2dujNT0vyIWCBJtq+XdLyk9uGsTyGcAQCAPJXSrfkpSXMl/YOkzygJV2eXsNx4SYszw83puPbeYfsx27+1vW9mfEj6ve2HbZ/V2ZPYPst2k+2mlpaWEsraOQ0DGwhnAAAgN6VcrbnR9g8k3Slpq5KrNTeVsG53MC7aDT8iaVJErLF9tKSbJU1Lpx0cEUtsj5H0B9t/7egihIi4XNLlkjRjxoz26y+7xrpGPb386byfBgAA7KJKubfmMZKelfQfkn4gab7t95Ww7mZJEzPDEyQtyc4QEasiYk36+HZJtbZHpcNL0t9LJd2kpJu04hrrGrlaEwAA5KbUqzUPj4jDIuJdkg5XaVdrPiRpmu0ptgdIOknSLdkZbO/Wdmso2zPTepbbHmK7Ph0/RNKRkp4odaPyxDlnAAAgT6VcELA0IuZnhhdIWtrdQhGxxfanldz+qVrSlREx1/bZ6fTLJJ0o6VO2t0haL+mkiAjbYyXdlOa2GknXRUQhbhnVWNeoNZvWaMvWLaqpKqX5AAAASldKuphr+3ZJNyg5Z+xDSr4W4wOSFBG/6mzBtKvy9nbjLss8/oGSrtL2yy2Q9JZSNqC3NfBsLNQAAB9bSURBVNY1SkruEjBy8MgKVwMAAPqbUsJZnaSXJb0rHW6RNELScUrCWqfhrD9qC2crNqwgnAEAgLIr5WrNT/RGIX1FNpwBAACUWylXa+5l+07bT6TD+9v+Sv6lFdO2m59zxSYAAMhBKVdr/ljS+ZI2S1JEPK7kystdEkfOAABAnkoJZ4Mj4sF247bkUUxfQDgDAAB5KiWcLbM9Vem3+9s+UdKLuVZVYIQzAACQp1Ku1vx7JbdHeqPtFyQ9p+Tm57uk+oH1skw4AwAAuSjlas0Fkt6dflN/VUSszr+s4qpylRrquPk5AADIR8lfcR8Ra/MspC/h/poAACAvpZxzhna4vyYAAMgL4WwHNAykWxMAAOSjpG5N2++UNDk7f0RcnVNNhddY16jnVjxX6TIAAEA/1G04s/0zSVMlzZHUmo4OSbt0OOPIGQAAyEMpR85mSNonIiLvYvqKYQOHaeUGLggAAADlV8o5Z09I2i3vQvqShoENWrVxlcirAACg3Do9cmb7N0q6L+slPWn7QUkb26ZHxPvzL6+YGuoaFAqt2bRG9QPrK10OAADoR7rq1vxur1XRxzQMbJAkrdy4knAGAADKqtNwFhH3SpLtKZJejIgN6fAgSWN7p7xiaqhLw9mGlZowbEKFqwEAAP1JKeec/ULS1sxwazpulzVs4DBJ0qqNqypcCQAA6G9KCWc1EbGpbSB9PCC/koov260JAABQTqWEsxbb207+t328pGX5lVR82W5NAACAcirle87OlnSt7R9IsqTFkj6ea1UFx5EzAACQl27DWUQ8K+nttodKckSszr+sYuOcMwAAkJdS7615jKR9JdXZliRFxEU51lVoQwcMVZWr6NYEAABl1+05Z7Yvk/QRSecq6db8kKRJOddVaLaTWzjRrQkAAMqslAsC3hkRH5f0akT8q6R3SJqYb1nF1zCwgXAGAADKrpRwtj79vc72OEmbJU3Jr6S+YdjAYZxzBgAAyq6Uc85utd0o6d8kPaLkfptX5FpVH9BQ18A5ZwAAoOxKuVrza+nDX9q+VVJdROzyqaRhYINeXPNipcsAAAD9TCkXBAy2/VXbP46IjZLG2D62F2orNI6cAQCAPJRyztlPJW1UciGAJDVL+npuFfURwwZwzhkAACi/UsLZ1Ij4jpILARQR65V8pcYuraGOqzUBAED5lRLONtkepORCANmequRI2i6tYWCDNrVu0oYtGypdCgAA6EdKuVrzXyTdIWmi7WslHSzp9DyL6guyNz+vG1pX4WoAAEB/UcrVmn+w/YiktyvpzvxMRCzLvbKCy95fc+zQsRWuBgAA9Bcl3VszIpZLui3nWvqUhoHpkTPOOwMAAGVUyjln6EC2WxMAAKBcCGc7iCNnAAAgD6V8Ce3PShm3q2msa5QkrdiwosKVAACA/qSUI2f7ZgdsV0t6Wz7l9B2EMwAAkIdOw5nt822vlrS/7VXpz2pJSyX9utcqLKj6gfWqchXhDAAAlFWn4SwivhUR9ZL+LSKGpT/1ETEyIs4vZeW2j7I9z/Z82+d1MP0w2yttz0l/Lih12UqrcpUaBjYQzgAAQFmV8j1n59seLmmapLrM+NldLZd2f14q6T1K7sf5kO1bIuLJdrPeFxHH7uCyFdVY16hXN7xa6TIAAEA/0m04s32GpM9ImiBpjpIvo/2TpL/pZtGZkuZHxIJ0PddLOl5SKQFrZ5btNY11jRw5AwAAZVXKBQGfkXSgpEURcbikt0pqKWG58ZIWZ4ab03HtvcP2Y7Z/a7vt4oNSl5Xts2w32W5qaSmlrPIhnAEAgHIrJZxtiIgNkmR7YET8VdLeJSznDsZFu+FHJE2KiLdI+i9JN/dg2WRkxOURMSMiZowePbqEsspn+KDhhDMAAFBWpYSzZtuNSoLTH2z/WtKSUpaTNDEzPKH9chGxKiLWpI9vl1Rre1QpyxZB48BGvbqec84AAED5lHJBwN+mDy+0fbekBkl3lLDuhyRNsz1F0guSTpL00ewMtneT9HJEhO2ZSsLickkrulu2COjWBAAA5VbSjc/bRMS9PZh3i+1PS/qdpGpJV0bEXNtnp9Mvk3SipE/Z3iJpvaSTIiIkdbhsT2rtDY11jVq7ea02t25WbXVtpcsBAAD9QI/CWU+lXZW3txt3WebxDyT9oNRli2b4oOGSkvtrjho8qsLVAACA/oAbn++Etls4cd4ZAAAol1JufD7EdlX6eC/b77dNH564vyYAACi/Uo6czZZUZ3u8pDslfULSVXkW1VcQzgAAQLmVEs4cEeskfUDSf6VXb+6Tb1l9A+EMAACUW0nhzPY7JJ0i6bZ0XK4XEvQVw+uSCwIIZwAAoFxKCWeflXS+pJvSr8LYU9Ld+ZbVN2y7IICbnwMAgDIp5Uto75V0rySlFwYsi4h/yLuwvmBw7WDVVNVw5AwAAJRNKVdrXmd7mO0hkp6UNM/2F/Ivrfhsc5cAAABQVqV0a+4TEasknaDkS2H3kPSxXKvqQ4bXcfNzAABQPqWEs9r0e81OkPTriNgsKfItq+9orGvknDMAAFA2pYSzH0laKGmIpNm2J0lalWdRfQndmgAAoJy6DWcR8Z8RMT4ijo7EIkmH90JtfQLhDAAAlFMpFwQ02P53203pz/eUHEWDOOcMAACUVyndmldKWi3pw+nPKkk/zbOovqSxrpEbnwMAgLIp5Zv+p0bEBzPD/2p7Tl4F9TWNdY3a2LpRG7ZsUF1NXaXLAQAAfVwpR87W2z6kbcD2wZLW51dS38L9NQEAQDmVcuTsbElX225Ih1+VdFp+JfUt2XC229DdKlwNAADo60q5fdNjkt5ie1g6vMr2ZyU9nndxfcHwQcnNzznvDAAAlEMp3ZqSklCW3ilAkj6XUz19Dt2aAACgnEoOZ+24rFX0YYQzAABQTjsazrh9U4pwBgAAyqnTc85sr1bHIcySBuVWUR8zvC4954z7awIAgDLoNJxFRH1vFtJXDawZqEE1g/TK+lcqXQoAAOgHdrRbExkjB4/U8vXLK10GAADoBwhnZTBy0EgtX0c4AwAAO49wVgYjB4+kWxMAAJQF4awMRg6iWxMAAJQH4awMRgwaQbcmAAAoC8JZGYwclHRrRvD1bwAAYOcQzspg5OCRao1Wrdy4stKlAACAPo5wVgYjB42UJLo2AQDATiOclcHIwUk444pNAACwswhnZbDtyBlXbAIAgJ1EOCuDtiNndGsCAICdRTgrgxGDRkjiyBkAANh5hLMyGF43XJY5cgYAAHYa4awMqquq1VjXyJEzAACw0whnZcL9NQEAQDkQzsqE+2sCAIByIJyVycjBIznnDAAA7LRcw5nto2zPsz3f9nldzHeg7VbbJ2bGLbT9F9tzbDflWWc5cOQMAACUQ01eK7ZdLelSSe+R1CzpIdu3RMSTHcz3bUm/62A1h0fEsrxqLKcRg0Zw5AwAAOy0PI+czZQ0PyIWRMQmSddLOr6D+c6V9EtJS3OsJXcjB43U6k2rtal1U6VLAQAAfVie4Wy8pMWZ4eZ03Da2x0v6W0mXdbB8SPq97Ydtn5VblWXSdpeAV9e/WuFKAABAX5ZnOHMH46Ld8CWSvhgRrR3Me3BEHCDpfZL+3vahHT6JfZbtJttNLS0tO1fxTuD+mgAAoBzyDGfNkiZmhidIWtJunhmSrre9UNKJkn5o+wRJiogl6e+lkm5S0k36OhFxeUTMiIgZo0ePLu8W9AD31wQAAOWQZzh7SNI021NsD5B0kqRbsjNExJSImBwRkyXdKOmciLjZ9hDb9ZJke4ikIyU9kWOtO40jZwAAoBxyu1ozIrbY/rSSqzCrJV0ZEXNtn51O7+g8szZjJd1ku63G6yLijrxqLQeOnAEAgHLILZxJUkTcLun2duM6DGURcXrm8QJJb8mztnIbMWiEJI6cAQCAncMdAspkSO0QDagewP01AQDATiGclYnt5C4BdGsCAICdQDgro1GDR2nZ+j5xQwMAAFBQhLMyGjNkjJau7dM3OgAAABVGOCsjwhkAANhZhLMyIpwBAICdRTgro7FDxmrVxlXasGVDpUsBAAB9FOGsjMYMGSNJHD0DAAA7jHBWRoQzAACwswhnZdQWzl5e83KFKwEAAH0V4ayMxg4dK4kjZwAAYMcRzspo9ODRkqSX13LkDAAA7BjCWRkNGTBEQ2qHcOQMAADsMMJZmfFdZwAAYGcQzsps7NCxdGsCAIAdRjgrM46cAQCAnUE4K7MxgwlnAABgxxHOymzMkDFqWduirbG10qUAAIA+iHBWZmOHjlVrtGr5uuWVLgUAAPRBhLMyGzsk+SJaLgoAAAA7gnBWZuOHjZckLVm9pMKVAACAvohwVmbj6sdJkl5Y9UKFKwEAAH0R4azMdh+6uySOnAEAgB1DOCuzQbWDNLxuOOEMAADsEMJZDsbVj9OSNYQzAADQc4SzHIwfNp4jZwAAYIcQznIwrn4c4QwAAOwQwlkOxg0dpxdXv6jWra2VLgUAAPQxhLMcjKsfp9ZoVcu6lkqXAgAA+hjCWQ7avuuMrk0AANBThLMccJcAAACwowhnOeDIGQAA2FGEsxyMHTJWlrmFEwAA6DHCWQ5qq2s1duhYNa9qrnQpAACgjyGc5WRy42QtWrmo0mUAAIA+hnCWk0kNk7RwxcJKlwEAAPoYwllOJjdO1vMrn9fW2FrpUgAAQB9COMvJpIZJ2rx1s15c/WKlSwEAAH0I4SwnkxsnSxJdmwAAoEcIZzkhnAEAgB1BOMvJHg17SBJXbAIAgB7JNZzZPsr2PNvzbZ/XxXwH2m61fWJPly2qIQOGaPTg0Rw5AwAAPZJbOLNdLelSSe+TtI+kk23v08l835b0u54uW3STGidx5AwAAPRInkfOZkqaHxELImKTpOslHd/BfOdK+qWkpTuwbKFNbpzMkTMAANAjeYaz8ZIWZ4ab03Hb2B4v6W8lXdbTZTPrOMt2k+2mlpaWnS66nCY3TNaiFYv4rjMAAFCyPMOZOxgX7YYvkfTFiGjdgWWTkRGXR8SMiJgxevToHSgzP3sO31MbWzdyA3QAAFCymhzX3SxpYmZ4gqQl7eaZIel625I0StLRtreUuGzh7T1qb0nSvOXzNLFhYjdzAwAA5Hvk7CFJ02xPsT1A0kmSbsnOEBFTImJyREyWdKOkcyLi5lKW7Qv2HpmGs2XzKlwJAADoK3I7chYRW2x/WslVmNWSroyIubbPTqe3P8+s22XzqjUv4+rHaeiAoZq3nHAGAABKk2e3piLidkm3txvXYSiLiNO7W7avsa29Ru6lp5c/XelSAABAH8EdAnK298i9OXIGAABKRjjL2d4j99aiFYu0fvP6SpcCAAD6AMJZzvYetbdCofmvzK90KQAAoA8gnOVs2xWbdG0CAIASEM5yttfIvSRJT7U8VeFKAABAX0A4y9mQAUP0hhFv0GMvP1bpUgAAQB9AOOsF03ebrjkvzal0GQAAoA8gnPWCt+72Vj376rNatXFVpUsBAAAFRzjrBdN3my5JeuwlujYBAEDXCGe9oC2c0bUJAAC6QzjrBbsP3V2jB48mnAEAgG4RznqBbU3fbboefenRSpcCAAAKjnDWSw7Y/QA9sfQJrdu8rtKlAACAAiOc9ZJD9jhEm7du1oMvPFjpUgAAQIERznrJwRMPlmXdt+i+SpcCAAAKjHDWS4YPGq79xuyn+54nnAEAgM4RznrRrD1m6U/Nf9KWrVsqXQoAACgowlkvmjVpltZsWsNXagAAgE4RznrRoZMOlSTdueDOClcCAACKinDWi8bVj9P03abrtmduq3QpAACgoAhnvey4vY7TA4sf0PJ1yytdCgAAKCDCWS87bq/jtDW26rfzf1vpUgAAQAERznrZ28a9TbsN3U2/efo3lS4FAAAUEOGsl1W5Su/f6/267enbtHbT2kqXAwAACoZwVgGn7H+K1m5eq5v/enOlSwEAAAVDOKuAQ/Y4RJMaJunqx6+udCkAAKBgCGcVUOUqnbr/qfrjgj9qyeollS4HAAAUCOGsQk57y2naGlt1+cOXV7oUAABQIISzCpk2cpqOmXaMfvjQD7Vhy4ZKlwMAAAqCcFZBn3vH59SyrkXX/eW6SpcCAAAKgnBWQYdPPlzTd5uui++/WJtbN1e6HAAAUACEswqyrYsOu0jPvPKMrnjkikqXAwAACoBwVmHH7nWsZu0xSxfee6FWb1xd6XIAAECFEc4qzLa+e+R31bK2RV+680uVLgcAAFQY4awAZo6fqXNnnqtLH7pU9z9/f6XLAQAAFUQ4K4hvHPENTWqcpFN+dYqWrVtW6XIAAECFEM4KYuiAofrFh36hl9e8rJNuPImrNwEA2EURzgpkxrgZuuzYy3Tnc3fq9F+frq2xtdIlAQCAXlZT6QKwvdOnn66X1ryk8+88XzVVNbriuCtUW11b6bIAAEAvIZwV0HmHnKctW7foq3d/VcvWLdMNJ96gIQOGVLosAADQC+jWLKivHPoV/ejYH+mO+Xdo1k9n6Znlz1S6JAAA0AtyDWe2j7I9z/Z82+d1MP1424/bnmO7yfYhmWkLbf+lbVqedRbVWW87S785+TdatHKRDrj8AF356JWchwYAQD/niMhnxXa1pKclvUdSs6SHJJ0cEU9m5hkqaW1EhO39Jd0QEW9Mpy2UNCMiSv5eiRkzZkRTU//Lcc2rmnXKr07R7EWzte/ofXXyfifriD2P0AG7H6AB1QMqXR4AANgBth+OiBntx+d5ztlMSfMjYkFawPWSjpe0LZxFxJrM/EMk5ZMU+7gJwybo7tPu1o1P3qhvP/BtfeXur+grd39FtVW12nfMvpq+23TtP2Z/TR0xVXsO31NTGqdwjhoAAH1UnuFsvKTFmeFmSQe1n8n230r6lqQxko7JTApJv7cdkn4UEZd39CS2z5J0liTtscce5am8gKpcpQ/v+2F9eN8Pq2Vti+5ZeI8eefERzXl5ju6Yf4eumnPVdvOPGTJG4+rHaeyQsRo7dGzyO33cWNeohoENaqhr2Pa4fmC9qswpiAAAVFqe3ZofkvTeiDgjHf6YpJkRcW4n8x8q6YKIeHc6PC4iltgeI+kPks6NiNldPWd/7dYsxbJ1y7Tg1QV67tXntODVBVrw6gK9uOZFvbz2Zb285mW9vPZlbWrd1OnyllU/sF4NAxs0uHawBtcO1qDaQcnvmkGvDddsP62upk4DqgeU9FNbVdvptOqqatVU1aja1bLdiy0HAEBlVKJbs1nSxMzwBElLOps5Imbbnmp7VEQsi4gl6filtm9S0k3aZTjblY0aPEqjBo/SzPEzO5weEVq5caWWrl2qFRtWaOWGlVq5ceW2323jVm1apXWb12nd5nVav3m91m5aq2Xrlm03bt3mdVq/ZX1u21LlKlU7DWuZ0NZ+uKtpHQ1XuUq2ZVm2k+H0seXSpvd0/h5M72ycpO0Ca/txbcOljutqXbvi+rtS6j8KlVhfkWur1PqKXFvR11ep2nZGnv/IV7lKh046NLf1dyfPcPaQpGm2p0h6QdJJkj6ancH2GyQ9m14QcICkAZKW2x4iqSoiVqePj5R0UY619nu21VjXqMa6xrKsLyK0YcsGrd+yXptbN2tT6yZt3pr8LuWnbZlNrZu0sXWjWre2qjVatWXrFrVuTX93NtzB+M6W2dS6SVu2btGWrVu0NbYqIhQKRUQynD7ubFx3y5RzOgCgGAbVDNK6L6+r2PPnFs4iYovtT0v6naRqSVdGxFzbZ6fTL5P0QUkft71Z0npJH0mD2lhJN6WpuEbSdRFxR161oudsa1DtIA2qHVTpUvqV9gFO0nbBrf247GkJpYzral274vq7UmpgrsT6ilxbpdZX5NqKvr5K1bYz8v6HttLnYOd2zlkl7MrnnAEAgL6ls3POuDwPAACgQAhnAAAABUI4AwAAKBDCGQAAQIEQzgAAAAqEcAYAAFAghDMAAIACIZwBAAAUCOEMAACgQAhnAAAABUI4AwAAKBDCGQAAQIEQzgAAAAqEcAYAAFAghDMAAIACcURUuoaysd0iaVHOTzNK0rKcn6Ovo426Rvt0jzbqGu3TPdqoa7RP93qjjSZFxOj2I/tVOOsNtpsiYkal6ygy2qhrtE/3aKOu0T7do426Rvt0r5JtRLcmAABAgRDOAAAACoRw1nOXV7qAPoA26hrt0z3aqGu0T/doo67RPt2rWBtxzhkAAECBcOQMAACgQAhnAAAABUI4K5Hto2zPsz3f9nmVrqdSbF9pe6ntJzLjRtj+g+1n0t/DM9POT9tsnu33Vqbq3mN7ou27bT9le67tz6TjaaOU7TrbD9p+LG2jf03H00YZtqttP2r71nSY9smwvdD2X2zPsd2UjqONMmw32r7R9l/Tz6R30EYJ23un+07bzyrbny1M+0QEP938SKqW9KykPSUNkPSYpH0qXVeF2uJQSQdIeiIz7juSzksfnyfp2+njfdK2GihpStqG1ZXehpzbZ3dJB6SP6yU9nbYDbfRaG1nS0PRxraT/J+nttNHr2ulzkq6TdGs6TPts3z4LJY1qN4422r49/lvSGenjAZIaaaMO26la0kuSJhWlfThyVpqZkuZHxIKI2CTpeknHV7imioiI2ZJeaTf6eCUfAkp/n5AZf31EbIyI5yTNV9KW/VZEvBgRj6SPV0t6StJ40UbbRGJNOlib/oRoo21sT5B0jKQrMqNpn+7RRinbw5T8M/0TSYqITRGxQrRRR46Q9GxELFJB2odwVprxkhZnhpvTcUiMjYgXpSScSBqTjt+l2832ZElvVXJkiDbKSLvs5khaKukPEUEbbe8SSf8saWtmHO2zvZD0e9sP2z4rHUcbvWZPSS2Sfpp2j19he4hoo46cJOl/0seFaB/CWWncwTi+g6R7u2y72R4q6ZeSPhsRq7qatYNx/b6NIqI1IqZLmiBppu39uph9l2oj28dKWhoRD5e6SAfj+m37ZBwcEQdIep+kv7d9aBfz7optVKPkFJT/GxFvlbRWSTddZ3bFNpLtAZLeL+kX3c3awbjc2odwVppmSRMzwxMkLalQLUX0su3dJSn9vTQdv0u2m+1aJcHs2oj4VTqaNupA2s1yj6SjRBu1OVjS+20vVHIKxd/Yvka0z3YiYkn6e6mkm5R0MdFGr2mW1JwelZakG5WENdpoe++T9EhEvJwOF6J9CGeleUjSNNtT0pR9kqRbKlxTkdwi6bT08WmSfp0Zf5LtgbanSJom6cEK1NdrbFvJOR5PRcS/ZybRRinbo203po8HSXq3pL+KNpIkRcT5ETEhIiYr+ay5KyJOFe2zje0htuvbHks6UtIToo22iYiXJC22vXc66ghJT4o2au9kvdalKRWlfSp9lURf+ZF0tJIr756V9OVK11PBdvgfSS9K2qzkP4m/kzRS0p2Snkl/j8jM/+W0zeZJel+l6++F9jlEyaHuxyXNSX+Opo22a6P9JT2attETki5Ix9NGr2+rw/Ta1Zq0z2vbu6eSK+cekzS37TOZNnpdO02X1JS+126WNJw22q59BktaLqkhM64Q7cPtmwAAAAqEbk0AAIACIZwBAAAUCOEMAACgQAhnAAAABUI4AwAAKBDCGYDCsB22v5cZ/ifbF/bi8w+0/Ufbc2x/pLeeN33uhbZH9eZzAigmwhmAItko6QMVDClvlVQbEdMj4ucVqgHALo5wBqBItki6XNI/tp9g+yrbJ2aG16S/D7N9r+0bbD9t+2Lbp9h+0PZfbE/tYF0jbN9s+3Hbf7a9v+0xkq6RND09cja13TJTbd+R3mj7PttvzNR1WTru6fTemLJdZ/unaQ2P2j48HV9t+7vp+Mdtn5t5mnNtP5JOa1v/u9J65qTrqd/JNgZQcDWVLgAA2rlU0uO2v9ODZd4i6U2SXpG0QNIVETHT9mcknSvps+3m/1dJj0bECbb/RtLVETHd9hmS/ikiju3gOS6XdHZEPGP7oP/f3t2zRhVEYRz/P/EFREHRykbUyKKFiC8giBDwC1ilMYWKFmIgWPgBLGOhWImihZjKKFaCkEJRCIgiGFdBsfClsRGRBTGBdY/FzIUhZldDCq/L84Nl787cuWfYYjmcmWWAy8Ch3LcZGAIGgYeStgGjABGxMydaU5IawHFgC7A7ItqS1hcxvkTEHkmngbPAyfw+GhHTktYAs4v4XszsP+TKmZnVSkS0gJvA2CKGPYuIzxExRzpeZSq3N0mJ03wHgYkc7wGwQdLabg/PSdEB4LakF8BVYGNxy2REdCLiHSk53D4vxhvgI9AgnSV6JSLaue9r8Zy7+f15Me9p4KKkMWBdNc7M+peTMzOro0ukc1tXF21t8m9WPmB+ZdE3V1x3is8dFl4h0AJtvc6yGwC+5b1o1WtHj7HRJUYVu1usat4/yfOOiHFSBW0V8KRa7jSz/uXkzMxqJ1eTJkkJWuUDsDdfHwZWLCHEY2AE0p410nJiq8d8WsB7ScN5jCTtKm4ZljSQ96ltJR2MXMZoAJty+xRwStLy3Fcua/5G0mBENCPiPOkQaydnZn3OyZmZ1dUFoPzX5jVgSNJTYD/wfQnPPgfsk/QSGAeO/sWYEeCEpBngNSlBrLwFHgH3SfvSZkl70pZJagK3gGN52fU68Im0r24GOPKHuGckvcr3/sgxzKyPKaJXJd/MzHqRdAO4FxF3/vVczKw/uHJmZmZmViOunJmZmZnViCtnZmZmZjXi5MzMzMysRpycmZmZmdWIkzMzMzOzGnFyZmZmZlYjvwDt0CKcFy+SkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "plt.plot(Loss, color = 'r')\n",
    "plt.plot(Keras_model.history.history[\"loss\"], color = 'g')\n",
    "plt.legend([\"Own \", \"Keras\"])\n",
    "plt.title(\"Loss of algorithm at each epoch, comparing own and keras implementation: \\n\")\n",
    "plt.xlabel(\"Num of epochs \")\n",
    "plt.ylabel(\"Loss at each epoch\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:52:00.154881Z",
     "start_time": "2020-06-10T04:52:00.146938Z"
    },
    "code_folding": [
     0,
     20,
     34
    ]
   },
   "outputs": [],
   "source": [
    "def dictionary_to_vector(parameters):\n",
    "    \"\"\"\n",
    "    Roll all our parameters dictionary into a single vector satisfying our specific required shape.\n",
    "    \"\"\"\n",
    "    keys = []\n",
    "    count = 0\n",
    "    for key in [\"theta1\", \"theta2\", \"theta3\"]:\n",
    "        \n",
    "        # flatten parameter\n",
    "        new_vector = np.reshape(parameters[key], (-1,1))\n",
    "        keys = keys + [key]*new_vector.shape[0]\n",
    "        \n",
    "        if count == 0:\n",
    "            theta = new_vector\n",
    "        else:\n",
    "            theta = np.concatenate((theta, new_vector), axis=0)\n",
    "        count = count + 1\n",
    "\n",
    "    return theta, keys\n",
    "\n",
    "def vector_to_dictionary(theta):\n",
    "    \"\"\"\n",
    "    Unroll all our parameters dictionary from a single vector satisfying our specific required shape.\n",
    "    \"\"\"\n",
    "    parameters = {}\n",
    "    parameters[\"theta1\"] = theta[:12].reshape((4,3))\n",
    "#     parameters[\"b1\"] = theta[20:25].reshape((5,1))\n",
    "    parameters[\"theta2\"] = theta[12:21].reshape((3,3))\n",
    "#     parameters[\"b2\"] = theta[40:43].reshape((3,1))\n",
    "    parameters[\"theta3\"] = theta[21:].reshape((3,1))\n",
    "#     parameters[\"b3\"] = theta[46:47].reshape((1,1))\n",
    "\n",
    "    return parameters\n",
    "\n",
    "def gradients_to_vector(gradients):\n",
    "    \"\"\"\n",
    "    Roll all our gradients dictionary into a single vector satisfying our specific required shape.\n",
    "    \"\"\"\n",
    "    \n",
    "    count = 0\n",
    "    for key in [\"DW1\", \"DW2\", \"DW3\"]:\n",
    "        # flatten parameter\n",
    "        new_vector = np.reshape(gradients[key], (-1,1))\n",
    "        \n",
    "        if count == 0:\n",
    "            theta = new_vector\n",
    "        else:\n",
    "            theta = np.concatenate((theta, new_vector), axis=0)\n",
    "        count = count + 1\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:52:00.164827Z",
     "start_time": "2020-06-10T04:52:00.155846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'theta1': array([[ 0.21167032,  0.0899986 ,  0.65491521],\n",
       "        [ 1.73611677, -0.22690361, -0.22035332],\n",
       "        [ 0.09260403,  0.18581741,  0.72391082],\n",
       "        [-0.04426139, -0.83601255, -0.24377559]]),\n",
       " 'theta2': array([[-0.20044229, -0.83772159,  0.04443767],\n",
       "        [-0.33219047, -0.58186041,  0.70410224],\n",
       "        [-0.47156783, -0.41789769,  0.3474615 ]]),\n",
       " 'theta3': array([[-0.0260292 ],\n",
       "        [ 0.08038196],\n",
       "        [-0.04618847]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:52:00.172801Z",
     "start_time": "2020-06-10T04:52:00.165821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DW1': array([[ 0.00037581,  0.00583802,  0.00308186],\n",
       "        [-0.00037064, -0.00624158, -0.00257465],\n",
       "        [ 0.00049052,  0.00791522,  0.00390025],\n",
       "        [ 0.00048873,  0.00784107,  0.00381596]]),\n",
       " 'DW2': array([[ 0.        ,  0.        , -0.01215476],\n",
       "        [ 0.        ,  0.        , -0.00446355],\n",
       "        [ 0.        ,  0.        ,  0.01289029]]),\n",
       " 'DW3': array([[ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [-0.01723276]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:52:00.178784Z",
     "start_time": "2020-06-10T04:52:00.173799Z"
    }
   },
   "outputs": [],
   "source": [
    "parameter_values,_ = dictionary_to_vector(parameters)\n",
    "grad = gradients_to_vector(Derivatives)\n",
    "numparams = parameter_values.shape[0]\n",
    "J_plus = np.zeros((numparams, 1))\n",
    "J_minus = np.zeros((numparams, 1))\n",
    "gradapprox = np.zeros((numparams, 1))\n",
    "ep = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:52:00.186763Z",
     "start_time": "2020-06-10T04:52:00.181776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:52:00.245625Z",
     "start_time": "2020-06-10T04:52:00.188758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 , loss: 0.6938988100472632\n",
      "Epoch: 0 , loss: 0.6938988099721018\n",
      "Epoch: 0 , loss: 0.6938988105934847\n",
      "Epoch: 0 , loss: 0.6938988094258803\n",
      "Epoch: 0 , loss: 0.6938988103178682\n",
      "Epoch: 0 , loss: 0.6938988097014966\n",
      "Epoch: 0 , loss: 0.6938988099726187\n",
      "Epoch: 0 , loss: 0.693898810046746\n",
      "Epoch: 0 , loss: 0.693898809385525\n",
      "Epoch: 0 , loss: 0.6938988106338403\n",
      "Epoch: 0 , loss: 0.6938988097522177\n",
      "Epoch: 0 , loss: 0.6938988102671473\n",
      "Epoch: 0 , loss: 0.6938988100587347\n",
      "Epoch: 0 , loss: 0.6938988099606305\n",
      "Epoch: 0 , loss: 0.6938988108012042\n",
      "Epoch: 0 , loss: 0.6938988092181608\n",
      "Epoch: 0 , loss: 0.693898810399707\n",
      "Epoch: 0 , loss: 0.6938988096196579\n",
      "Epoch: 0 , loss: 0.6938988100585557\n",
      "Epoch: 0 , loss: 0.6938988099608092\n",
      "Epoch: 0 , loss: 0.6938988107937892\n",
      "Epoch: 0 , loss: 0.6938988092255758\n",
      "Epoch: 0 , loss: 0.6938988103912781\n",
      "Epoch: 0 , loss: 0.6938988096280869\n",
      "Epoch: 0 , loss: 0.6938988100096825\n",
      "Epoch: 0 , loss: 0.6938988100096825\n",
      "Epoch: 0 , loss: 0.6938988100096825\n",
      "Epoch: 0 , loss: 0.6938988100096825\n",
      "Epoch: 0 , loss: 0.6938988087942062\n",
      "Epoch: 0 , loss: 0.6938988112251586\n",
      "Epoch: 0 , loss: 0.6938988100096825\n",
      "Epoch: 0 , loss: 0.6938988100096825\n",
      "Epoch: 0 , loss: 0.6938988100096825\n",
      "Epoch: 0 , loss: 0.6938988100096825\n",
      "Epoch: 0 , loss: 0.6938988095633275\n",
      "Epoch: 0 , loss: 0.6938988104560377\n",
      "Epoch: 0 , loss: 0.6938988100096825\n",
      "Epoch: 0 , loss: 0.6938988100096825\n",
      "Epoch: 0 , loss: 0.6938988100096825\n",
      "Epoch: 0 , loss: 0.6938988100096825\n",
      "Epoch: 0 , loss: 0.6938988112987119\n",
      "Epoch: 0 , loss: 0.6938988087206532\n",
      "Epoch: 0 , loss: 0.6938988100096825\n",
      "Epoch: 0 , loss: 0.6938988100096825\n",
      "Epoch: 0 , loss: 0.6938988100096825\n",
      "Epoch: 0 , loss: 0.6938988100096825\n",
      "Epoch: 0 , loss: 0.6938988082864064\n",
      "Epoch: 0 , loss: 0.6938988117329592\n"
     ]
    }
   ],
   "source": [
    "for i in range(numparams):\n",
    "    \n",
    "    thetaplus = np.copy(parameter_values)\n",
    "    thetaplus[i][0] = thetaplus[i][0] + ep\n",
    "    \n",
    "    _, _, _, J_plus[i] = do(lr = 1e-2 , epochs = 1, algo = \"GD\", nesterov = True, Use_new=True,\n",
    "                           dictionary = vector_to_dictionary(thetaplus))\n",
    "    \n",
    "#     J_plus[i], _ =  forward_propagation_n(X, Y, vector_to_dictionary(thetaplus))  # Step 3\n",
    "    \n",
    "    \n",
    "    thetaminus = np.copy(parameter_values)                                       # Step 1\n",
    "    thetaminus[i][0] = thetaminus[i][0] - ep                                # Step 2        \n",
    "    \n",
    "    _, _, _, J_minus[i] = do(lr = 1e-2 , epochs = 1, algo = \"GD\", nesterov = True, Use_new=True,\n",
    "                           dictionary = vector_to_dictionary(thetaminus))\n",
    "    \n",
    "#     J_minus[i], _ = forward_propagation_n(X, Y, vector_to_dictionary(thetaminus)) # Step 3\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Compute gradapprox[i]\n",
    "    ### START CODE HERE ### (approx. 1 line)\n",
    "    gradapprox[i] = ( (J_plus[i] - J_minus[i]) / (2 * ep) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:52:00.251621Z",
     "start_time": "2020-06-10T04:52:00.246653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.508205033454513e-08"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerator = np.linalg.norm((grad - gradapprox) )                                    # Step 1'\n",
    "denominator = np.linalg.norm(grad) + np.linalg.norm(gradapprox)                   # Step 2'\n",
    "difference = numerator / denominator                                              # Step 3'\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T04:52:00.259570Z",
     "start_time": "2020-06-10T04:52:00.252588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference > 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Amith_Learning",
   "language": "python",
   "name": "amith_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
